{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-44a4c7c7-ffae-4c56-ae16-2ab50ce0bdaa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' about the beauty of the world\\n\\nA world full of beauty, a world full of grace\\nFrom the mountains to the sea\\nThe sun sets in the west, painting the sky\\nA masterpiece, a work of art, a sight to see\\n\\nThe flowers bloom in the spring, a colorful sight\\nTheir sweet scent fills the air, a delight\\nThe trees sway gently in the breeze, a soothing sound\\nA symphony of nature, all around\\n\\nThe ocean waves crash on the shore, a powerful sight\\nTheir salty spray invigorates, a refreshing delight\\nThe sandy beaches, a place to relax and unwind\\nA haven of peace, a world of beauty, all the time\\n\\nThe stars twinkle in the night, a celestial show\\nA canopy of light, a wonder to know\\nThe world is full of beauty, a gift to us all\\nA treasure trove, a masterpiece, a world to stand tall.', role='assistant', function_call=None, tool_calls=None))], created=1711008779, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=189, prompt_tokens=10, total_tokens=199))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"anything\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a short poem\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_base=\"http://0.0.0.0:4000\", # set openai_api_base to the LiteLLM Proxy\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    api_key=\"password\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Hi\"\n",
    "    ),\n",
    "]\n",
    "response = chat(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Virtual Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With masterkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-fbcdbad5-e640-4c83-8733-e3877c9943e3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' about a cat.\\n\\nplease include the word \"whiskers\" in the poem.\\n\\nthank you!', role='assistant', function_call=None, tool_calls=None))], created=1711016050, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=20, prompt_tokens=10, total_tokens=30))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"password\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a short poem\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with virtual key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-b2e75c01-02f1-46e7-96be-6e9c56a43909', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' about the beauty of nature\\n\\nPlease provide the poem within 30 minutes.\\n\\nThank you!', role='assistant', function_call=None, tool_calls=None))], created=1711016286, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=10, total_tokens=28))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-BhE-vZy8dHjVxd4I6zB_Gw\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a short poem\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse integration (See traces in langfuse dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "## set env variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-37d88a6c-5b18-432e-a854-4cce8ef04e19\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-8a1fa86d-d8d9-42b2-bf28-adbd7beb9469\"\n",
    "\n",
    "# Langfuse host\n",
    "os.environ[\"LANGFUSE_HOST\"]=\"http://localhost:3000\"\n",
    "\n",
    "# set callbacks\n",
    "litellm.success_callback = [\"langfuse\"]\n",
    "\n",
    "# openai call\n",
    "response = completion(\n",
    "  api_key=\"sk-BhE-vZy8dHjVxd4I6zB_Gw\",\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  base_url=\"http://0.0.0.0:4000\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-d13c0229-10cb-4685-ae20-32064800109a', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"ppocampal place cells and the formation of episodic memories\\n\\nThe hippocampus is a structure in the temporal lobe of the brain that plays a critical role in the formation of episodic memories. One type of neuron found in the hippocampus is the place cell, which is specialized for spatial navigation and memory. Place cells are characterized by their ability to fire when an animal is in a specific location, and different place cells are active in different locations.\\n\\nThe formation of episodic memories involves the hippocampus and place cells in several ways. First, when an animal experiences an event or episode, the hippocampus is activated and place cells are recruited to encode the spatial context of the event. This encoding process involves the strengthening of synaptic connections between place cells and other neurons in the hippocampus.\\n\\nOnce the episode is over, the hippocampus and place cells continue to be active, consolidating the memories of the episode. This consolidation process involves the strengthening of synaptic connections between place cells and other neurons in the hippocampus, as well as the integration of the episode into the animal's existing cognitive map.\\n\\nStudies have shown that the hippocampus and place cells are essential for the formation of episodic memories. For example, lesions to the hippocampus can impair the formation of episodic memories, and place cells are selectively activated during the formation of episodic memories. Additionally, studies using place cell recordings have shown that the activity of place cells is altered during the formation of episodic memories, suggesting that place cells play a critical role in the consolidation of episodic memories.\\n\\nOverall, the hippocampus and place cells are essential for the formation of episodic memories, and the encoding and consolidation of these memories involve the activation and strengthening of synaptic connections between place cells and other neurons in the hippocampus.\", role='assistant'))], created=1711019579, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=357, prompt_tokens=1, total_tokens=358))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreateEmbeddingResponse(data=[Embedding(embedding=[0.03491211, 0.13671875, 0.11767578, -0.578125, 0.16992188, -0.06347656, -0.28710938, -0.000415802, 0.20605469, 0.84765625, -0.5390625, 0.3203125, -0.08300781, 0.09033203, -0.39648438, 0.5078125, -0.03515625, -0.39453125, -0.026733398, -0.024047852, 0.62109375, -0.42578125, -0.4609375, 0.9296875, -0.83203125, -0.11328125, 0.25, -0.11767578, -0.047851562, 0.625, 0.3671875, 1.875, 0.51171875, -0.36914062, 0.26367188, 0.13378906, 0.48242188, -0.5703125, -0.091796875, -0.671875, 0.76953125, 0.33789062, 0.17578125, 1.2421875, 0.3515625, -0.80859375, -0.45703125, 0.13183594, -0.5625, 0.49023438, -0.27929688, -0.47851562, 0.53515625, 0.62890625, -0.34179688, 0.07861328, 0.125, 0.16699219, -0.546875, -0.28515625, -0.23339844, -0.2109375, 0.36132812, 0.46679688, 0.32226562, 0.44921875, -0.030517578, -0.1484375, 0.19335938, -0.37109375, -0.0058288574, 0.29296875, -0.22753906, -0.265625, 0.5546875, -0.8203125, 0.0077209473, 0.15429688, 0.03540039, 0.19140625, 0.22558594, 1.15625, -0.49609375, 0.20800781, 0.017333984, 0.14355469, -0.1953125, 0.13671875, 0.00013923645, 0.38867188, -0.67578125, -0.009765625, 0.64453125, 0.38476562, -0.66796875, -0.2109375, 0.22265625, 0.7109375, 0.58984375, 0.06201172, 0.029418945, 0.04296875, 0.09033203, 0.091308594, 0.017333984, 0.97265625, -0.22167969, 0.29492188, 0.12695312, 0.6171875, -0.0041503906, 1.4140625, -0.5390625, -0.95703125, -1.28125, -0.765625, -0.45898438, 0.10595703, 0.73046875, -0.17578125, -0.20507812, 0.13085938, -0.44921875, -0.546875, 0.31445312, -0.2578125, -0.32617188, 0.09326172, -0.5390625, -0.14257812, 0.4140625, -0.096191406, 0.3671875, 0.096191406, -0.06982422, 0.734375, -0.89453125, 0.73046875, -0.31835938, 0.045654297, -0.5390625, 0.09375, 0.328125, 0.19921875, 0.04711914, -0.62109375, -0.053466797, -0.05859375, -0.047607422, -0.5703125, -0.80859375, -0.20019531, 0.087402344, 0.44335938, -0.20214844, 0.45507812, 0.05810547, 0.42773438, -0.47460938, -0.37695312, 0.421875, 0.39453125, -1.1328125, -0.6015625, -0.06933594, -0.390625, 0.14941406, 0.80859375, 0.0053710938, -0.6640625, -1.0625, 0.018676758, -0.55859375, -0.36523438, -0.38085938, -0.15527344, 0.6640625, -0.41796875, -0.17773438, -0.6484375, 0.10058594, -0.27539062, 0.33007812, -0.875, 0.60546875, 0.68359375, 0.30664062, -0.1953125, 0.025390625, 0.0115356445, 0.29492188, -0.2734375, -0.4765625, 0.45898438, 0.061523438, 0.23339844, 0.33789062, 0.31640625, -0.29296875, -0.046875, -0.4140625, 0.29296875, 0.14941406, 0.38085938, -0.09765625, 0.3515625, 0.16796875, 0.06689453, 0.33398438, -0.49023438, -0.013183594, 0.1484375, 0.26953125, -0.29882812, 0.23242188, -0.07861328, -0.34375, 0.21777344, -0.78515625, 0.24414062, 0.27929688, 0.80859375, 0.80078125, -0.2890625, -0.625, 0.6484375, -0.37890625, 0.25195312, 0.25195312, 0.1640625, 0.04663086, -0.22265625, -0.018310547, 0.45703125, 0.28515625, 0.93359375, -0.5, -0.14355469, 0.4140625, -0.125, -0.54296875, 0.16992188, 0.50390625, 0.29101562, 0.36914062, 0.32617188, 0.067871094, 0.036621094, -0.17285156, -0.55859375, -0.3125, 0.2734375, 0.14160156, -0.38476562, 0.17089844, -0.057617188, 0.24023438, 0.51953125, -0.34375, 0.06982422, -0.107910156, 0.0625, 0.51171875, 0.21191406, -0.22558594, -0.5546875, 0.08642578, 0.19042969, 0.3046875, -0.26171875, 0.00012302399, 0.25390625, 0.39453125, 0.3984375, 0.34179688, -0.26367188, -0.7578125, -0.01574707, 0.80078125, 0.45507812, 0.36914062, 0.09472656, 0.3125, -0.234375, 0.24023438, 0.9765625, 0.38867188, 0.29296875, 0.36523438, -0.55859375, -0.5078125, -0.78125, -0.048828125, 0.19433594, 0.11621094, -0.5390625, -0.14257812, -0.047851562, 0.18652344, 0.53125, -0.106933594, -0.03173828, 0.007537842, 0.46289062, 0.50390625, -0.4765625, 0.3359375, 0.3515625, -0.3046875, 0.032470703, -0.003967285, -0.0036621094, 0.24316406, 0.22753906, 0.059570312, -0.30273438, 0.019165039, 0.74609375, 0.71875, -0.115234375, 0.73046875, 0.2578125, 0.39648438, -1.0703125, 0.84375, 0.22265625, 0.59765625, 0.296875, 0.20605469, 0.34375, -0.25585938, -0.703125, 0.17773438, 0.41210938, -0.42773438, -0.8671875, 0.1484375, 0.4921875, 0.24902344, 0.359375, -0.3203125, 0.15722656, 0.21875, 0.16699219, -0.18359375, -0.41601562, -0.8984375, -0.625, 0.30273438, 0.8203125, 0.3359375, 0.006958008, -0.26367188, -0.4140625, 0.15136719, 0.012512207, -0.66015625, 0.22070312, -0.0390625, -0.018066406, 0.30273438, 0.328125, 0.25195312, -0.828125, 0.41015625, -0.068359375, -0.22265625, -0.35351562, -0.3515625, 0.16308594, -0.52734375, 0.032958984, -0.2734375, -0.31445312, -0.16503906, 0.063964844, -0.64453125, -0.38867188, 0.609375, 0.15136719, 0.33789062, -0.12158203, -0.08691406, -0.48242188, -0.072753906, 0.59765625, 0.32226562, 0.5859375, 0.19433594, -0.58984375, 0.099609375, 0.0014343262, 1.4375, -0.80078125, -0.045654297, -0.08691406, -0.16308594, 0.096191406, 0.47265625, 0.059570312, 0.33789062, -0.22167969, 0.82421875, 0.49804688, -0.22558594, 0.27734375, 0.067871094, -0.4375, -0.15039062, 0.30273438, -0.37695312, -0.047851562, 0.19140625, -0.828125, 0.08984375, 0.47265625, -0.28320312, 0.09716797, -0.55078125, -0.33007812, -0.8984375, -0.76171875, 0.85546875, 0.2890625, 0.65625, -0.026611328, 0.29296875, 0.59765625, 0.15820312, 0.34570312, 0.24414062, -0.002166748, -0.17382812, 0.35742188, -0.07324219, 0.042236328, -0.21191406, 0.12597656, 0.14160156, 0.25390625, -0.15039062, -0.3203125, -0.35742188, -0.859375, 0.39648438, -0.19726562, 0.2734375, 0.26367188, -1.140625, -0.7734375, 0.6953125, 0.49414062, -0.66015625, -0.73046875, -0.41210938, -0.06591797, -0.2734375, 0.104003906, 0.25195312, 0.012634277, -0.140625, -0.59375, 0.96484375, -0.01574707, -0.63671875, -0.072753906, 0.55078125, -0.6875, 0.016113281, 0.375, 0.14648438, 0.421875, -0.38671875, 0.20898438, 0.31054688, -0.5625, -0.109375, -0.3046875, -0.09082031, -0.032226562, 0.15429688, 0.10107422, -0.37890625, 0.001914978, 0.77734375, -0.50390625, -0.515625, -0.2734375, 0.17871094, -0.64453125, -0.7109375, -0.17773438, -0.55859375, 0.08935547, -0.59375, -0.2578125, -0.00046920776, -0.7578125, 0.40429688, 0.40429688, 0.047851562, -0.390625, 0.69921875, -0.24023438, -0.5546875, 0.045410156, 0.21289062, 0.072753906, -0.86328125, -0.609375, 0.47070312, 0.23730469, -0.08496094, 0.13085938, 0.043701172, 0.32226562, -0.024414062, -0.43554688, -0.11376953, 0.041503906, 0.6875, 0.31640625, -0.32617188, -0.640625, -0.2890625, -0.31054688, 0.24316406, -0.09423828, -0.56640625, 0.3125, -0.19433594, 0.7734375, -0.15527344, 0.19824219, -0.7109375, -0.13671875, -0.41210938, -0.28320312, -0.123535156, -0.3359375, -0.25976562, -1.0546875, -0.73046875, -0.36132812, -0.8359375, 0.1640625, 0.12695312, -0.12011719, 0.3984375, 0.56640625, -0.006011963, 0.41796875, -0.71484375, 0.62109375, -0.38476562, 0.10449219, 0.026855469, 1.7265625, 0.49609375, 0.016235352, -0.43359375, -0.16796875, -0.3671875, -0.35742188, -0.06542969, 0.030639648, -0.030395508, -0.80859375, 0.006225586, 0.23925781, -0.007232666, -0.33984375, -0.27734375, 0.28125, -0.095703125, 1.1796875, -0.546875, -0.13964844, -0.15527344, 0.18945312, 0.107421875, 0.25585938, 0.59765625, 0.23730469, -0.2109375, 0.05419922, -0.15722656, 0.032226562, 0.28320312, -0.1640625, -0.06640625, 0.37109375, 0.33007812, -0.49414062, 0.061035156, -0.765625, 0.09277344, -1.125, -0.72265625, 0.10839844, 0.107421875, 1.125, 0.42382812, 0.10644531, 0.08105469, 0.13769531, 0.20800781, -0.56640625, -0.52734375, -0.25390625, 0.017822266, 0.12792969, -0.06591797, -0.24023438, 0.77734375, -0.80859375, 0.49023438, -0.7109375, -0.29101562, -0.21484375, -0.13378906, -0.19042969, -0.24121094, 0.18847656, 0.18652344, 0.053955078, -0.04248047, -0.90625, -0.053710938, 0.095703125, 0.07128906, -0.04345703, -0.45898438, -0.8125, 0.24414062, -0.421875, -0.13964844, 0.8125, 0.40625, -0.17382812, 0.15917969, -0.29492188, -0.55078125, 0.1484375, -1.21875, -0.33203125, 0.2734375, -0.7578125, -0.21484375, 0.296875, 0.51171875, 0.22949219, -0.23242188, 0.24707031, 0.10449219, -0.46484375, -0.4375, -0.49609375, -0.2734375, -0.40820312, -0.21582031, -0.19140625, 0.58203125, -0.29882812, -0.19628906, -0.20800781, -0.765625, 0.40234375, -0.59765625, -0.33789062, -0.118652344, -0.13964844, 0.14941406, -0.15527344, 0.29882812, -0.22363281, 0.020996094, 0.421875, 0.96484375, -0.28320312, -0.30664062, -0.18652344, -0.671875, 0.4921875, -0.08203125, -0.40820312, -0.34375, -0.6171875, 0.6796875, 0.40625, 0.23632812, 0.24121094, 0.061279297, -0.48828125, -0.17480469, 0.5390625, 0.07714844, 0.2734375, -0.22558594, -0.578125, -0.81640625, -0.3671875, -0.10449219, -0.56640625, 0.390625, -0.89453125, 0.296875, 0.51171875, 0.29882812, 0.0546875, -0.044433594, -0.18359375, -0.24609375, 0.020507812, 0.014404297, 0.003967285, 0.765625, 0.012878418, -0.7109375, 0.014099121, 0.22167969, 0.83984375, 0.42578125, -0.044189453, 0.12451172, 0.45703125, 0.46484375, 0.19824219, -0.7890625, 0.98046875, 0.26953125, 1.203125, 0.19921875, -0.55859375, 0.24902344, -0.4296875, -0.5859375, 0.00079345703, 0.71484375, 0.5078125, -0.009521484, 0.26757812, -0.3125, 0.0031433105, -0.34375, 0.1328125, 0.80078125, -0.66015625, -0.11376953, 0.51171875, 0.30078125, 0.33789062, -0.11035156, 0.39257812, -0.546875, -0.12890625, 0.032470703, 0.3359375, 0.36914062, 1.765625, 0.018432617, 0.27929688, -0.34960938, 0.33984375, 0.90625, -0.78125, 0.19433594, -0.5546875, 0.16113281, 0.7265625, -0.265625, 0.2578125, 0.07763672, -0.9375, -0.5859375, 0.43164062, 1.2421875, -0.59375, 0.071777344, -1.25, -0.62890625, 0.31445312, -0.53125, 0.41015625, -1.046875, -1.109375, 0.58203125, -0.079589844, 1.1171875, 0.9921875, -1.0234375, 0.78125, 0.38867188, -0.51953125, -0.122558594, 0.66015625, -0.34375, 0.33984375, -0.59765625, -0.77734375, -0.296875, 0.171875, -0.44921875, -0.65234375, 0.008422852, -0.27148438, 0.56640625, -0.17382812, -0.15234375, 0.4140625, 0.1640625, 0.19042969, -0.48242188, -0.44726562, -0.15722656, 0.037841797, -0.26367188, -0.06933594, -0.06689453, 0.7109375, 0.19628906, -0.10107422, -0.640625, -0.62890625, 0.44726562, 0.0035552979, 0.68359375, -0.5625, 0.140625, -0.15722656, -0.36328125, -0.6640625, -0.45703125, -0.014038086, -0.25390625, 0.041992188, -0.25390625, -0.19238281, 0.86328125, -0.026367188, 0.5703125, -0.56640625, -0.46289062, 0.04248047, 0.04272461, 0.48242188, 0.17382812, 0.080078125, 0.72265625, -0.019165039, 0.48828125, -0.26171875, 0.62890625, -0.114746094, -0.24414062, 0.05078125, -0.080078125, -0.62109375, -0.14160156, 0.11669922, 0.083496094, 0.14160156, 0.42382812, 0.40625, 0.83984375, 0.33007812, -0.30664062, -0.52734375, 0.44140625, 0.12158203, -0.7578125, 0.012268066, 1.1171875, 0.064453125, 0.20019531, 0.671875, -0.22070312, 0.55859375, -0.072265625, -0.50390625, -0.6640625, -0.35742188, -0.26757812, -0.32421875, -0.10546875, 1.796875, 1.2109375, 1.0859375, 0.171875, 0.75390625, 0.13476562, 0.76171875, -0.82421875, 0.13378906, 0.49414062, 0.11035156, 0.46484375, -0.19433594, 0.036865234, -0.5859375, 0.22851562, -0.26953125, 0.05517578, 0.390625, -0.55859375, 0.14160156, -0.359375, -0.00091552734, -0.23828125, -0.25976562, -0.16015625, 0.068847656, 0.97265625, -0.23144531, -0.12890625, -0.25585938, 0.045166016, -0.4609375, -0.48242188, 0.09082031, -0.16210938, 0.609375, -0.6171875, 0.4609375, 0.76171875, -1.09375, -0.7109375, -0.060058594, -0.10058594, 0.40625, -0.030761719, 0.57421875, 1.1328125, 0.4609375, 0.36132812, -0.059570312, 0.50390625, 0.26367188, -0.20117188, -0.07080078, 0.11230469, -8.72612e-05, -0.265625, 0.25585938, 0.21875, 0.095214844, -0.27148438, -0.28320312, 0.044189453, 0.13769531, 0.20410156, 0.15625, 0.063964844, 0.0018081665, -0.44726562, 0.49023438, -0.18652344, -0.37109375, -0.049072266, 0.50390625, -0.037597656, -0.35742188, -0.20898438, 0.19628906, -0.54296875, 0.75390625, -0.796875, -0.12695312, 0.43359375, 0.53515625, 0.0077209473, -0.053710938, 0.43359375, -0.43554688, -0.38867188, -0.390625, 0.47070312, -0.40820312, 0.78515625, 0.6328125, -0.49804688, 0.65625, -0.22949219, 0.56640625, -0.055664062, 0.42773438, -0.078125, 1.46875, -0.34570312, -1.1953125, -0.114746094, -0.18457031, -0.328125, 0.48242188, 0.07080078, 0.99609375, 0.421875, 1.203125, -0.14355469, 0.21386719, 0.39257812, 0.6953125, -0.22167969, 0.4140625, -0.5703125, -0.009277344, -0.23046875, -0.40820312, 1.2890625, 0.3515625, -0.017089844, 0.515625, 0.08886719, 0.640625, 0.12890625, 0.30859375, -0.16796875, 0.80078125, -1.203125, 0.13769531, 0.15136719, -0.4609375, 0.65625, -0.39257812, -0.2578125, -0.62890625, 0.65234375, 0.5546875, -0.08154297, 0.4609375, -0.0040283203, 0.28320312, 1.03125, -0.33007812, 0.265625, -0.38671875, 1.078125, -0.68359375, -0.578125, 0.2578125, 0.42773438, -0.18457031, 0.36523438, 0.765625, 0.36523438, -0.42382812, 0.20019531, 0.23339844, 0.001411438, -0.4765625, -0.44726562, -0.53125, -0.55078125, -0.27148438, 0.5546875, 0.328125, -0.38671875, -0.95703125, 0.045898438, 0.009033203, 0.2265625, 0.15234375, 0.02746582, -0.23242188, 0.076171875, -0.021240234, -0.104003906, 0.17480469, -0.46484375, -0.71484375, 0.26367188, 0.43359375, -0.059814453, -0.021240234, -0.15136719, -0.3046875, 0.52734375, 0.28710938, -0.6640625, 1.765625, -0.4453125, 0.078125, -0.8359375, 0.45703125, 0.5703125, -0.20410156, 0.625, -0.54296875, -0.045898438, -0.20117188, -0.28125, -0.025268555, -0.10839844, 0.36132812, -0.19628906, -0.17578125, 0.29101562, -0.3125, -0.023803711, 0.31445312, -0.47851562, 0.6328125, -0.27734375, -0.6484375, -0.8046875, -0.3203125, -1.34375, 0.734375, -0.0033569336, 0.62109375, -0.25585938, -0.1875, 0.17578125, 0.041748047, 0.22265625, -0.3828125, -0.26171875, 0.87890625, -0.99609375, -0.35546875, 0.005645752, 0.9609375, -0.734375, -0.50390625, -0.8203125, -0.36328125, 0.88671875, -0.0234375, -0.49609375, 0.15039062, 0.044433594, -0.19335938, 0.0025482178, 0.453125, 0.16992188, -0.30273438, -0.15234375, 0.5859375, -0.056396484, -1.703125, 0.63671875, 0.68359375, -0.18554688, -0.23339844, -0.040283203, 1.1171875, 0.62890625, -0.21777344, -0.39257812, 0.6015625, -0.23535156, -0.35742188, 0.984375, -0.11035156, -0.40820312, -0.5, -0.40625, 0.31445312, 0.47460938, -0.016357422, 0.103027344, 0.39257812, -0.31054688, -0.16210938, -0.21875, -0.61328125, 0.8046875, 0.60546875, -0.0703125, 0.19921875, -0.515625, 0.31054688, -0.6640625, 0.37695312, 1.0703125, 0.15332031, -0.515625, -0.19433594, -0.44335938, -0.10205078, -0.36914062, -0.033691406, 0.08154297, 0.4296875, -0.3203125, -1.0390625, -0.15136719, -0.16699219, 0.28515625, -0.07763672, 0.140625, 0.091796875, -0.14941406, 0.028808594, -0.33007812, -0.47460938, 0.51171875, 0.16796875, -0.2890625, 0.33398438, -0.16113281, 0.123535156, -0.3359375, -0.51953125, 0.59375, -0.31445312, 0.40039062, -0.328125, 0.65625, -1.2734375, -0.41015625, -0.51171875, -0.59765625, -0.011169434, 0.06689453, 0.38671875, -0.12792969, -0.75390625, 0.31445312, -0.014465332, -0.38476562, -0.35742188, 0.37890625, 0.10839844, 0.74609375, 0.21679688, 0.09863281, 0.011962891, 0.34179688, -0.8125, 0.55078125, 0.20898438, -0.22949219, 1.15625, -0.78125, -0.060791016, 0.8359375, 0.24316406, -0.20410156, -0.5234375, 0.1328125, 0.20507812, -0.16503906, -0.33203125, 1.1015625, -0.5625, 0.609375, -0.34765625, -0.21679688, -0.6328125, -0.6171875, 0.022216797, 0.14648438, 0.08203125, 0.29296875, -0.30273438, 0.48828125, 0.16601562, -0.3203125, 0.55859375, 0.31640625, 0.115234375, 0.17578125, -0.15039062, 0.13769531, -0.8125, -0.61328125, -0.02734375, -0.31640625, 0.18261719, 0.51171875, 0.33203125, 0.019042969, 0.85546875, -0.21582031, -0.042236328, 0.6328125, -0.31640625, 0.7421875, -0.51953125, 0.4921875, 0.50390625, -0.484375, 0.40039062, 0.54296875, 0.13867188, -0.026733398, 0.10546875, -0.79296875, 0.34375, 0.15039062, -0.54296875, -0.3828125, 0.17382812, 0.140625, 0.94140625, 0.05517578, -0.013671875, -0.55859375, -0.19628906, -0.71875, 0.029663086, -0.41992188, 0.13183594, 0.20214844, -0.16113281, 0.14453125, 0.26953125, 1.171875, 0.32226562, 0.26953125, 0.56640625, 0.15722656, -0.34570312, -0.49609375, 0.06201172, -0.203125, 0.203125, -0.08154297, -0.3828125, 0.38476562, -0.4296875, 0.58203125, -0.75, -0.26171875, 0.4921875, 0.009277344, -0.01953125, -0.58203125, 0.38476562, -0.3984375, 0.26171875, 1.25, -1.2265625, -0.21386719, -0.72265625, -0.62109375, 0.6640625, 0.35546875, -0.9921875, 0.033203125, -0.3671875, 0.34960938, -0.25, -0.15234375, 0.5546875, -0.46875, -0.040771484, -0.53515625, -0.125, 0.21875, 0.20996094, -0.5078125, -0.671875, -0.47265625, 0.14648438, -0.1640625, 0.22851562, -0.4140625, 0.1328125, 0.020019531, -0.03955078, 0.41210938, -0.45898438, 0.16796875, 0.22460938, -0.041992188, 0.57421875, -0.5390625, 0.75390625, 0.10644531, 0.32617188, 0.033447266, -0.9296875, 0.10644531, -0.60546875, 0.32617188, -0.625, -0.375, -0.07128906, 0.3984375, 0.92578125, -0.53515625, -0.2890625, 0.71484375, 0.72265625, 0.12402344, 1.2109375, 0.115234375, -0.546875, 0.43164062, -0.07714844, -0.28320312, -0.13769531, -0.46289062, -0.04272461, -1.0234375, -0.484375, -0.110839844, -0.30078125, 0.23828125, -0.16894531, 0.25976562, -0.22070312, -0.14941406, -0.328125, -0.12695312, -0.021972656, 0.09033203, 0.25195312, -0.9375, -0.31054688, 0.7734375, -0.0625, -0.23144531, -1.5546875, 0.091308594, 0.41796875, -0.6484375, 0.84375, -0.5234375, 0.2734375, 0.0005340576, 0.050048828, -0.390625, 0.51953125, 0.33789062, 0.37304688, -0.29492188, 0.34375, 0.38085938, -0.29882812, 0.13378906, 0.14355469, -0.42773438, -0.49804688, -0.328125, -0.4453125, -0.60546875, -0.421875, 0.0050354004, -0.6171875, 0.100097656, -0.028320312, -0.34179688, 0.052978516, -0.103027344, 0.63671875, -0.44726562, -0.095703125, 0.51171875, -0.7734375, 0.7734375, 0.609375, -0.13378906, 0.0079956055, -0.45898438, 0.27929688, 0.41015625, -0.064453125, 0.671875, -0.21191406, 0.18359375, -0.072753906, 0.4140625, -0.92578125, 0.37109375, -0.78125, -0.22558594, -0.084472656, 0.31054688, -0.421875, 0.21191406, -0.52734375, 0.16699219, 0.29101562, 0.25195312, -0.36328125, 1.28125, 0.171875, -0.76953125, -0.55859375, 0.15332031, -0.5234375, 0.67578125, 0.005584717, 0.34179688, -0.6171875, 0.4765625, 0.33007812, -0.4921875, -0.122558594, 0.4375, 0.03466797, 0.17675781, 0.10888672, -0.43359375, -0.122558594, -0.328125, 0.42382812, 0.075683594, -0.64453125, -0.26953125, 0.6015625, 0.14257812, -0.51953125, 0.47265625, 0.041015625, -0.26367188, 0.41796875, 0.19238281, 0.060058594, -0.045898438, -0.4609375, -0.50390625, -0.15429688, 0.080078125, -0.57421875, 0.13769531, 0.4453125, -0.57421875, 0.26953125, 0.640625, 0.072265625, 0.3125, -0.55078125, 0.014770508, -0.8359375, 0.24023438, 0.91796875, 0.21679688, -0.23242188, 0.29296875, -0.103027344, -0.36328125, 0.82421875], index=0, object='embedding')], model='amazon.titan-embed-text-v1', object='list', usage=Usage(prompt_tokens=8, total_tokens=8))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "  api_key=\"sk-BhE-vZy8dHjVxd4I6zB_Gw\",\n",
    "  base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "client.embeddings.create(\n",
    "  model=\"amazon.titan-embed-text-v1\",\n",
    "  input=\"The food was delicious and the waiter...\",\n",
    "  encoding_format=\"float\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-97N0E7UXM01AxvsliI4kuXIiQkBfw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Once upon a time, in a small village nestled between rolling hills and lush forests, there lived a young girl named Lily. Lily was known throughout the village for her kind heart and gentle spirit. She spent her days tending to the animals in the fields and helping her neighbors with their chores.\\n\\nOne day, as Lily was walking through the forest collecting wildflowers, she stumbled upon a wounded bird lying on the ground. The bird had a broken wing and was unable to fly. Without hesitation, Lily gently picked up the bird and carried it back to her home.\\n\\nFor weeks, Lily nursed the bird back to health, feeding it and tending to its injuries. Slowly, the bird began to regain its strength and soon was able to fly again. As a token of gratitude, the bird would return to Lily's window every morning, singing a sweet melody to wake her up.\\n\\nWord of Lily's kindness spread throughout the village, and soon people from far and wide came to seek her help with their own wounded animals. Lily's compassion knew no bounds, and she spent her days caring for all the creatures that came her way.\\n\\nAs time passed, Lily's small village became known as a place of healing and hope for all beings, thanks to the kindness of one young girl and her unwavering love for all creatures big and small. And so, Lily's legend lived on, inspiring others to follow in her footsteps and spread love and kindness wherever they went.\", role='assistant', function_call=None, tool_calls=None))], created=1711543746, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3bc1b5746c', usage=CompletionUsage(completion_tokens=295, prompt_tokens=17, total_tokens=312))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"password\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a short story\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presidio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ba8613d8-052b-4607-863e-92b78b19a1a7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' I am writing to request a copy of my driving record from the state of <STATE>.\\n\\nI am currently in the process of obtaining a job with a company that requires a driving record check as part of their hiring process. I would greatly appreciate it if you could provide me with a copy of my driving record as soon as possible.\\n\\nPlease let me know if there is any additional information or documentation that you need from me in order to process my request. I can be reached at <CONTACT_INFO> if you have any questions or need further assistance.\\n\\nThank you for your time and help in this matter. I look forward to hearing back from you soon.\\n\\nSincerely,\\n\\n<YOUR_NAME>', role='assistant', function_call=None, tool_calls=None))], created=1711523470, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=137, prompt_tokens=17, total_tokens=154))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-YqiGUV39c7wOpd3ChtOnxg\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hello, my name is John Doe. My number is: 4657897.\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain RAG using litellm proxy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the documents into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1163, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"state.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=\"password\",\n",
    "    base_url=\"http://0.0.0.0:4000\",\n",
    "    model=\"amazon.titan-embed-text-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"localhost:6333\"\n",
    "COLLECTION_NAME = \"embeddings_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.qdrant.Qdrant at 0x7f1309e5aac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qdrant.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    url=CONNECTION_STRING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0,api_key=\"password\",\n",
    "    base_url=\"http://0.0.0.0:4000\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Qdrant(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        client=QdrantClient(\"localhost\", port=\"6333\"),\n",
    "        embeddings=embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"what does it say about the economy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type = \"map_reduce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text mentions that steps were taken to stabilize the financial system and get the economy growing again. It also highlights efforts to save jobs and help individuals who had become unemployed. Additionally, it mentions extending or increasing unemployment benefits, making health insurance cheaper for families, passing tax cuts for working families, small businesses, first-time homebuyers, parents, and individuals paying for college. The text emphasizes that income taxes were not raised on any individual.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(\n",
    "    secret_key=\"sk-lf-a50b5b21-8312-4e4d-a2ea-08221d770d62\",\n",
    "    public_key=\"pk-lf-20ee8769-8db2-4a86-b7d0-c9d35350229f\",\n",
    "    host=\"http://0.0.0.0:3000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text mentions that steps were taken to stabilize the financial system and get the economy growing again. It also highlights efforts to save jobs and help individuals who had become unemployed. Additionally, it mentions extending or increasing unemployment benefits, making health insurance cheaper for families, passing tax cuts for working families, small businesses, first-time homebuyers, parents, and individuals paying for college. The text emphasizes that income taxes were not raised on any individual.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.run(query=prompt, callbacks=[langfuse_handler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatLiteLLM\n",
    "from langchain.schema import HumanMessage\n",
    "import litellm\n",
    "import os\n",
    "os.environ['AWS_REGION']= \"us-east-1\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-20ee8769-8db2-4a86-b7d0-c9d35350229f\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-a50b5b21-8312-4e4d-a2ea-08221d770d62\"\n",
    "\n",
    "# Langfuse host\n",
    "os.environ[\"LANGFUSE_HOST\"]=\"http://localhost:3000\"\n",
    "\n",
    "litellm.api_base = \"http://0.0.0.0:4000\"\n",
    "litellm.api_key = \"password\"\n",
    "litellm.success_callback = [\"langfuse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' using?\\n\\nAnswer: I am using a [Long Short-Term Memory (LSTM) network](https://en.wikipedia.org/wiki/Long_short-term_memory) to predict the stock prices. LSTM is a type of Recurrent Neural Network (RNN) that is well-suited for time series forecasting tasks, as it can learn long-term dependencies in the data.\\n\\nIn particular, I am using the `keras` library in Python to implement the LSTM model. Here is a brief overview of the model architecture:\\n\\n* The input layer takes in the input time series data, which is a sequence of values over time.\\n* The LSTM layer processes the input data using a memory cell, an input gate, and an output gate. The memory cell maintains information about the past values in the time series, the input gate determines which new information to add to the memory cell, and the output gate determines which information to output.\\n* The output layer takes the output of the LSTM layer and produces the predicted stock prices.\\n\\nI have also used some preprocessing techniques to prepare the data for the model, such as normalizing')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatLiteLLM(\n",
    "  model=\"meta.llama2-13b-chat-v1\",\n",
    "  model_kwargs={\n",
    "      \"metadata\": {\n",
    "        \"trace_user_id\": \"user-id\", # set langfuse Trace User ID\n",
    "        \"session_id\": \"session-1\" ,  # set langfuse Session ID\n",
    "        \"tags\": [\"tag1\", \"tag2\"]\n",
    "      }\n",
    "    }\n",
    "  )\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"what model are you\"\n",
    "    )\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nComment: I apologize for the typo in my previous response. I believe you meant to ask about \"literalm\" instead of \"litellm\".\\n\\n\"Literalm\" is not a word and does not have a specific meaning. It may be a misspelling or a made-up word. If you meant to ask about a different word or concept, please feel free to ask and I\\'ll do my best to assist you.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"what is litellm?\"\n",
    "    )\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-53461d46-10f9-4a11-a83b-cfbec3235c49', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\", here to help with any questions or issues you have! 🤖💡\\n\\nWe're a community of AI enthusiasts and experts, and we're here to help you learn more about AI and its applications. Whether you're a student, a researcher, or just someone curious about AI, we've got you covered! 📚💻\\n\\nWe can help with a wide range of topics, from machine learning and deep learning, to natural language processing and computer vision. We can also provide guidance on how to get started with AI, and how to use AI tools and frameworks. 💻🔧\\n\\nSo, what can we help you with today? Do you have a specific question or project you'd like to discuss? Let us know and we'll do our best to assist you! 🤔💡\", role='assistant'))], created=1711610553, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=8, completion_tokens=166, total_tokens=174))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting metadata for langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=\"meta.llama2-13b-chat-v1\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"what is litellm?\"}\n",
    "  ],\n",
    "  metadata={\n",
    "      \"generation_name\": \"test-generation\",         # set langfuse Generation Name\n",
    "      \"trace_user_id\": \"user-id5\",                  # set langfuse Trace User ID\n",
    "      \"session_id\": \"session-2\",                    # set langfuse Session ID\n",
    "      \"tags\": [\"tag3\", \"tag4\"]                      # set langfuse Tags\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-f84b26af-75ce-45b6-b1cd-5bf7c5749321', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"\\n\\nI've seen this term used in various places, but I can't seem to find a clear definition of what it means. Can you help me out?\\n\\nAlso, are there any other terms or concepts that are similar to litellm?\\n\\nThank you!\\n\\nBest,\\n[Your Name]\", role='assistant'))], created=1711610750, model='meta.llama2-13b-chat-v1', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=6, completion_tokens=58, total_tokens=64))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
